<!DOCTYPE html>
<html lang="zh">
<head>
  <meta charset="UTF-8" />
  <title>å®æ—¶æ‰‹åŠ¿è¿½è¸ªä¸éª¨æ¶ç»˜åˆ¶</title>
  <style>
    body {
      margin: 0;
      background: #000;
      color: #0f0;
      text-align: center;
      font-family: sans-serif;
    }
    #gestureName {
      font-size: 24px;
      margin-top: 10px;
    }
    #container {
      position: relative;
      display: inline-block;
    }
    video, canvas {
      width: 100%;
      max-width: 480px;
      border-radius: 10px;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
      pointer-events: none; /* ç¡®ä¿è§†é¢‘å¯äº¤äº’ */
    }
  </style>
</head>
<body>
  <h2>ğŸ–ï¸ å®æ—¶æ‰‹åŠ¿è¿½è¸ªä¸éª¨æ¶ç»˜åˆ¶</h2>
  <div id="gestureName">è¯†åˆ«ä¸­...</div>
  <div id="container">
    <video id="video" autoplay playsinline muted></video>
    <canvas id="canvas"></canvas>
  </div>

  <!-- ä¾èµ–åº“ -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
  <script src="https://cdn.jsdelivr.net/npm/fingerpose@0.1.0/dist/fingerpose.min.js"></script>

  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const gestureName = document.getElementById("gestureName");

    // åˆå§‹åŒ– fingerpose æ‰‹åŠ¿ä¼°è®¡å™¨ï¼Œä½¿ç”¨å†…ç½®æ‰‹åŠ¿
    const GE = new fp.GestureEstimator([
      fp.Gestures.ThumbsUpGesture,
      fp.Gestures.VictoryGesture,
      fp.Gestures.FistGesture,
      fp.Gestures.OpenPalmGesture,
    ]);

    // åˆå§‹åŒ– MediaPipe Hands
    const hands = new Hands({
      locateFile: (file) =>
        `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`,
    });

    hands.setOptions({
      maxNumHands: 1,
      modelComplexity: 1,
      minDetectionConfidence: 0.7,
      minTrackingConfidence: 0.7,
    });

    hands.onResults(onResults);

    // å¯åŠ¨æ‘„åƒå¤´
    async function startCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "user", width: 640, height: 480 },
      });
      video.srcObject = stream;

      video.onloadedmetadata = () => {
        video.play();
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        requestAnimationFrame(processVideo);
      };
    }

    // æŒç»­è°ƒç”¨ï¼Œå®æ—¶å¤„ç†è§†é¢‘å¸§
    async function processVideo() {
      // æ¯å¸§æŠŠå½“å‰è§†é¢‘å¸§å‘é€ç»™handsæ¨¡å‹è¿›è¡Œå¤„ç†
      await hands.send({ image: video });
      // é€’å½’è°ƒç”¨ï¼Œä¿è¯ä¸‹ä¸€å¸§ç»§ç»­å¤„ç†
      requestAnimationFrame(processVideo);
    }

    // handsæ¨¡å‹å¤„ç†ç»“æœå›è°ƒ
    function onResults(results) {
      // æ¸…ç©ºç”»å¸ƒï¼Œé¿å…éª¨æ¶æ®‹ç•™
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
        const landmarks = results.multiHandLandmarks[0];

        // ç»˜åˆ¶éª¨æ¶ï¼šè¿æ¥çº¿ + å…³é”®ç‚¹
        drawConnectors(ctx, landmarks, HAND_CONNECTIONS, {
          color: "#00FF00",
          lineWidth: 2,
        });
        drawLandmarksFn(ctx, landmarks, { color: "#FF0000", lineWidth: 1 });

        // ä½¿ç”¨ fingerpose ä¼°è®¡æ‰‹åŠ¿
        const est = GE.estimate(landmarks, 7.5);
        if (est.gestures.length > 0) {
          // æ‰¾å‡ºç½®ä¿¡åº¦æœ€é«˜çš„æ‰‹åŠ¿
          const best = est.gestures.reduce((p, c) =>
            p.score > c.score ? p : c
          );
          gestureName.innerText = `è¯†åˆ«åˆ°æ‰‹åŠ¿ï¼š${best.name}`;
        } else {
          gestureName.innerText = "æ‰‹åŠ¿æœªçŸ¥";
        }
      } else {
        // æ²¡æ£€æµ‹åˆ°æ‰‹ï¼Œæ¸…ç©ºéª¨æ¶ï¼Œæ˜¾ç¤ºæç¤º
        gestureName.innerText = "è¯†åˆ«ä¸­...";
      }
    }

    startCamera();
  </script>
</body>
</html>
