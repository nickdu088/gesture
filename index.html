<!DOCTYPE html>
<html lang="zh">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>å®æ—¶æ— åˆ·æ–°æ‰‹åŠ¿éª¨æ¶è·Ÿè¸ª</title>
  <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-black text-green-400 flex flex-col items-center min-h-screen p-4">
  <h1 class="text-3xl font-bold mb-4 select-none">ğŸ–ï¸ å®æ—¶æ— åˆ·æ–°æ‰‹åŠ¿éª¨æ¶è·Ÿè¸ª</h1>
  <div id="gestureName" class="mb-4 text-xl min-h-[2rem] select-none">è¯†åˆ«ä¸­...</div>

  <div id="container" class="relative w-full max-w-md rounded-lg shadow-lg overflow-hidden">
    <video
      id="video"
      autoplay
      playsinline
      muted
      class="w-full rounded-lg object-cover"
    ></video>
    <canvas
      id="canvas"
      class="absolute top-0 left-0 w-full h-full pointer-events-none"
    ></canvas>
  </div>

  <!-- MediaPipe Hands å’Œ fingerpose -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
  <script src="https://cdn.jsdelivr.net/npm/fingerpose@0.1.0/dist/fingerpose.min.js"></script>

  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const gestureName = document.getElementById("gestureName");

    // åˆå§‹åŒ– fingerpose æ‰‹åŠ¿ä¼°è®¡å™¨
    const GE = new fp.GestureEstimator([
      fp.Gestures.ThumbsUpGesture,
      fp.Gestures.VictoryGesture,
      fp.Gestures.FistGesture,
      fp.Gestures.OpenPalmGesture,
    ]);

    const hands = new Hands({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`,
    });

    hands.setOptions({
      maxNumHands: 1,
      modelComplexity: 1,
      minDetectionConfidence: 0.75,
      minTrackingConfidence: 0.75,
    });

    hands.onResults(onResults);

    async function startCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: "user", width: 640, height: 480 },
        });
        video.srcObject = stream;
        await video.play();

        // è®¾ç½®canvaså°ºå¯¸åŒ¹é…è§†é¢‘
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        // å¼€å§‹å¾ªç¯å¤„ç†è§†é¢‘å¸§
        requestAnimationFrame(processVideo);
      } catch (e) {
        gestureName.textContent = "æ‘„åƒå¤´å¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥æƒé™å’Œè®¾å¤‡";
        console.error(e);
      }
    }

    async function processVideo() {
      try {
        await hands.send({ image: video });
      } catch (error) {
        // å¦‚æœæ¨¡å‹å¶å°”å¼‚å¸¸ï¼Œæ‰“å°å¹¶ç»§ç»­
        console.warn("Hands.send() error:", error);
      }
      requestAnimationFrame(processVideo);
    }

    function onResults(results) {
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
        const landmarks = results.multiHandLandmarks[0];

        drawConnectors(ctx, landmarks, HAND_CONNECTIONS, {
          color: "#22c55e",
          lineWidth: 3,
        });
        drawLandmarksFn(ctx, landmarks, { color: "#dc2626", lineWidth: 2 });

        const est = GE.estimate(landmarks, 7.5);
        if (est.gestures.length > 0) {
          const best = est.gestures.reduce((p, c) => (p.score > c.score ? p : c));
          gestureName.textContent = `è¯†åˆ«åˆ°æ‰‹åŠ¿ï¼š${best.name}`;
        } else {
          gestureName.textContent = "æ‰‹åŠ¿æœªçŸ¥";
        }
      } else {
        gestureName.textContent = "è¯†åˆ«ä¸­...";
        // ç”»å¸ƒå·²æ¸…ç©ºï¼Œæ— éª¨æ¶æ˜¾ç¤º
      }
    }

    startCamera();
  </script>
</body>
</html>
